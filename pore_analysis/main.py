#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Molecular Dynamics Simulation Analysis Script (Refactored)
=========================================================

Main orchestrator script for analyzing molecular dynamics simulations
of toxin-channel complexes. Reads trajectories, performs various analyses
(distances, filtering, orientation, contacts, ions, water), and generates
reports and summaries for a SINGLE simulation run folder.

(Docstring content from original script regarding PURPOSE, DATA PROBLEMS, etc.
 can be retained or summarized here if desired)

See individual modules (core_analysis.py, filtering.py, ion_analysis.py, etc.)
for details on specific analysis implementations.

USAGE:
------
The script operates in two primary modes based on the flags provided:

1. Full Analysis (Default Workflow):
   - Command: `python -m pore_analysis.main --folder /path/to/run_directory`
   - Action: Runs all available analysis modules. Checks for a valid existing
     `analysis_summary.json` to potentially skip the run if results are
     up-to-date. Generates an HTML report by default.
   - To suppress the default report: Add `--no-report`.
   - To force re-running all analyses regardless of existing summary:
     Add `--force_rerun`. This also generates a report by default unless
     `--no-report` is specified.

2. Selective Analysis (Targeted Workflow):
   - Command: `python -m pore_analysis.main --folder /path/to/run --FLAG [--FLAG ...]`
     (e.g., `--ions --conduction`)
   - Action: Runs *only* the specified analysis modules (`--ions`, `--conduction` in the example).
     These analyses are always executed, overwriting previous results for these
     modules. The skip logic based on `analysis_summary.json` is bypassed.
   - Reporting: An HTML report is **NOT** generated by default in this mode.
   - To generate a report containing only the results from the executed modules:
     Add `--report`.

See `python -m pore_analysis.main --help` for all available flags.

"""

import argparse
import os
import sys
import logging
import json
from datetime import datetime
from collections import defaultdict
import traceback # For more detailed error logging
import numpy as np
import MDAnalysis as mda

# --- Import constants and functions from refactored modules ---
try:
    from pore_analysis.core.config import Analysis_version
    from pore_analysis.core.utils import frames_to_time, clean_json_data
    from pore_analysis.core.logging import setup_analysis_logger
    from pore_analysis.modules.core_analysis.core import analyze_trajectory, filter_and_save_data
    from pore_analysis.modules.orientation_contacts.orientation_contacts import analyze_toxin_orientation
    from pore_analysis.modules.ion_analysis import (
        track_potassium_ions, analyze_ion_coordination,
        analyze_ion_conduction
    )
    from pore_analysis.modules.ion_analysis.ion_conduction import plot_idealized_transitions
    from pore_analysis.modules.inner_vestibule_analysis import analyze_inner_vestibule as analyze_cavity_water
    from pore_analysis.reporting.summary import calculate_and_save_run_summary
    from pore_analysis.reporting.html import generate_html_report
    from pore_analysis.modules.gyration_analysis.gyration_core import analyze_carbonyl_gyration
    from pore_analysis.modules.tyrosine_analysis import analyze_sf_tyrosine_rotamers

except ImportError as e:
    print(f"ERROR: Failed to import necessary modules: {e}", file=sys.stderr)
    print("Please ensure the pore_analysis package is properly installed and structured.", file=sys.stderr)
    sys.exit(1)

# Try importing DW Gate separately
try:
    from pore_analysis.modules.dw_gate_analysis import analyse_dw_gates
except ImportError as e:
    # Log this specific failure but allow continuation
    logging.warning(f"Could not import dw_gate_analysis module: {e}. DW gate analysis will be skipped.")
    analyse_dw_gates = None # Define as None so checks later don't fail

def main():
    """
    Main execution function: parses arguments and orchestrates the analysis workflow.
    """
    parser = argparse.ArgumentParser(
        description=f"MD Simulation Analysis Script (v{Analysis_version}). Processes trajectories for a SINGLE run folder. See script docstring for detailed USAGE.",
        formatter_class=argparse.RawTextHelpFormatter # Keep RawTextHelpFormatter to preserve docstring formatting
    )
    # --- Input/Output & Mode Flags ---
    parser.add_argument("--trajectory", help="Path to a specific trajectory file (single mode - discouraged).")
    parser.add_argument("--topology", help="Path to a specific topology file (required for --trajectory mode).")
    parser.add_argument("--output", help="Output directory for results (used in --trajectory mode, defaults to trajectory dir).")
    parser.add_argument("--folder", required=True, help="Path to the specific run folder containing PSF/DCD (required).")
    parser.add_argument("--force_rerun", action="store_true", help="Force reprocessing of ALL modules, ignoring existing summary.")

    # --- Analysis Selection Flags --- (Added tyrosine, conduction, dwgates)
    analysis_group = parser.add_argument_group('Selective Analysis Flags (run only specified modules)')
    analysis_group.add_argument("--GG", action="store_true", help="Run G-G distance analysis.")
    analysis_group.add_argument("--COM", action="store_true", help="Run COM distance analysis.")
    analysis_group.add_argument("--orientation", action="store_true", help="Run Toxin orientation and contact analysis.")
    analysis_group.add_argument("--ions", action="store_true", help="Run K+ ion tracking and coordination analysis.")
    analysis_group.add_argument("--water", action="store_true", help="Run Cavity Water analysis.")
    analysis_group.add_argument("--gyration", action="store_true", help="Run Carbonyl Gyration analysis.")
    analysis_group.add_argument("--tyrosine", action="store_true", help="Run SF Tyrosine rotamer analysis.")
    analysis_group.add_argument("--conduction", action="store_true", help="Run Ion Conduction/Transition analysis.")
    analysis_group.add_argument("--dwgates", action="store_true", help="Run DW-Gate analysis.")

    # --- Other Options / Report Control ---
    other_group = parser.add_argument_group('Other Options')
    other_group.add_argument("--box_z", type=float, default=None, help="Provide estimated box Z-dimension (Angstroms) for multi-level COM filter.")
    other_group.add_argument("--log_level", default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"], help="Set the logging level.")
    other_group.add_argument("--report", action="store_true", help="Generate HTML report when running selective analyses.") # Changed help text
    other_group.add_argument("--no-report", action="store_true", help="Suppress HTML report generation when running full analysis (default or --force_rerun).") # Added flag

    args = parser.parse_args()

    # Logger setup is deferred until folder_path is known
    log_level_map = {"DEBUG": logging.DEBUG, "INFO": logging.INFO, "WARNING": logging.WARNING, "ERROR": logging.ERROR}
    root_log_level = log_level_map.get(args.log_level.upper(), logging.INFO)

    # --- Determine Which Analyses to Run ---
    specific_flags_set = args.GG or args.COM or args.orientation or args.ions or args.water or args.gyration or args.tyrosine or args.conduction or args.dwgates
    run_all_initially = not specific_flags_set # Run all if no specific flags are given

    run_gg = args.GG or run_all_initially
    run_com = args.COM or run_all_initially
    run_orientation = args.orientation or run_com
    run_ion_tracking = args.ions or args.water or args.conduction or run_all_initially
    run_ion_coordination = args.ions or run_all_initially
    run_water = args.water or run_all_initially
    run_gyration = args.gyration or run_all_initially
    run_tyrosine = args.tyrosine or run_all_initially
    run_conduction = args.conduction or run_all_initially
    run_dwgates = args.dwgates or run_all_initially

    # If --force_rerun, ensure all run flags are True
    if args.force_rerun:
        logging.info("Overriding analysis flags: --force_rerun specified, running ALL modules.")
        run_gg = True
        run_com = True
        run_orientation = True
        run_ion_tracking = True
        run_ion_coordination = True
        run_water = True
        run_gyration = True
        run_tyrosine = True
        run_conduction = True
        run_dwgates = True
        run_all_initially = True # Treat force_rerun as running all
        specific_flags_set = False # Treat force_rerun as NOT selective

    # --- Determine HTML Report Generation --- (New Logic)
    if specific_flags_set:
        # Selective Analysis mode: report only if --report is explicitly given
        generate_html = args.report
        if args.no_report:
             logging.warning("--no-report flag has no effect when running selective analyses.")
    else: # Full Analysis mode (default or --force_rerun)
        # Report by default, unless suppressed by --no-report
        generate_html = not args.no_report
        if args.report:
             logging.warning("--report flag is redundant when running full analysis (report is generated by default).")


    run_any_core_analysis = (run_gg or run_com or run_orientation or run_ion_tracking or
                             run_water or run_gyration or run_tyrosine or run_conduction or run_dwgates)

    # If somehow no analysis flags are set (shouldn't happen with current logic, but safety check)
    if not run_any_core_analysis and not args.trajectory:
         logging.error("Internal Error: No analysis modules selected to run. Exiting.")
         return


    # ============================
    # --- Single Trajectory Mode --- (Keep existing logic, but pass specific_flags_set)
    # ============================
    if args.trajectory:
        # ... (Argument validation) ...
        # --- Determine paths and names ---
        run_name = os.path.splitext(os.path.basename(args.trajectory))[0]
        output_dir = args.output if args.output else os.path.dirname(args.trajectory)
        os.makedirs(output_dir, exist_ok=True)
        parent_output_dir = os.path.dirname(output_dir)
        system_name = os.path.basename(parent_output_dir) if parent_output_dir and os.path.basename(parent_output_dir) else run_name

        # --- Setup Logger ---
        analysis_log_file = setup_analysis_logger(output_dir, run_name, root_log_level)
        if not analysis_log_file:
            return # Error printed by setup

        logging.info(f"--- MD Analysis Script v{Analysis_version} Started (Trajectory Mode) ---")
        # ... (Log command, paths, analysis plan) ...

        # --- Call Analysis Workflow ---
        try:
            success = _run_analysis_workflow(
                run_dir=output_dir, # Pass output_dir as run_dir
                system_name=system_name,
                run_name=run_name,
                psf_file=args.topology,
                dcd_file=args.trajectory,
                run_gg=run_gg, run_com=run_com, run_orientation=run_orientation,
                run_ion_tracking=run_ion_tracking, run_ion_coordination=run_ion_coordination,
                run_water=run_water, run_gyration=run_gyration, run_tyrosine=run_tyrosine,
                run_conduction=run_conduction, # Pass conduction flag
                run_dwgates=run_dwgates,           # Pass dwgates flag
                specific_analyses_requested=specific_flags_set, # Pass this info
                generate_html=generate_html,
                box_z=args.box_z,
                force_rerun=args.force_rerun
            )
            # ... (log success/failure) ...
        except Exception as e:
            # ... (log critical error)
            logging.critical(f"Unhandled error during trajectory processing: {e}", exc_info=True)
            _save_error_summary(output_dir, system_name, run_name, f"Unhandled Error: {e}")
        return # Ensure this is indented correctly

    # ========================
    # --- Single Folder Mode --- (Primary workflow, pass specific_flags_set)
    # ========================
    folder_path = os.path.abspath(args.folder)
    if not os.path.isdir(folder_path):
         print(f"ERROR: Specified folder does not exist: {folder_path}", file=sys.stderr)
         return

    run_name = os.path.basename(folder_path)
    parent_dir = os.path.dirname(folder_path)
    system_name = os.path.basename(parent_dir) if parent_dir and os.path.basename(parent_dir) else run_name

    # --- Setup Logger ---
    analysis_log_file = setup_analysis_logger(folder_path, run_name, root_log_level)
    if not analysis_log_file:
        return # Error printed by setup

    # --- Log initial info ---
    logging.info(f"--- MD Analysis Script v{Analysis_version} Started (Folder Mode) ---")
    # ... (Log command, system/run name, folder, analysis plan) ...
    logging.info(f"Full analysis requested: {not specific_flags_set}")
    logging.info(f"Generate HTML report: {generate_html}")


    # --- Prepare for workflow ---
    dcd_file = os.path.join(folder_path, "MD_Aligned.dcd")
    psf_file = os.path.join(folder_path, "step5_input.psf")

    if not os.path.exists(dcd_file) or not os.path.exists(psf_file):
        logging.error(f"Input files missing in {folder_path}. Aborting.")
        _save_error_summary(folder_path, system_name, run_name, "Input_File_Missing")
        return

    # --- Call Analysis Workflow ---
    try:
        success = _run_analysis_workflow(
            run_dir=folder_path,
            system_name=system_name,
            run_name=run_name,
            psf_file=psf_file,
            dcd_file=dcd_file,
            run_gg=run_gg, run_com=run_com, run_orientation=run_orientation,
            run_ion_tracking=run_ion_tracking, run_ion_coordination=run_ion_coordination,
            run_water=run_water, run_gyration=run_gyration, run_tyrosine=run_tyrosine,
            run_conduction=run_conduction, # Pass conduction flag
            run_dwgates=run_dwgates,           # Pass dwgates flag
            specific_analyses_requested=specific_flags_set, # Pass this info
            generate_html=generate_html,
            box_z=args.box_z,
            force_rerun=args.force_rerun
        )
        if success:
             logging.info(f"Analysis workflow completed successfully for {run_name}.")
        else:
             logging.warning(f"Analysis workflow finished with errors for {run_name}.")

    except Exception as e:
        # ... (log critical error) ...
        logging.critical(f"Unhandled error during single folder processing: {e}", exc_info=True)
        _save_error_summary(folder_path, system_name, run_name, f"Unhandled Error: {e}")

def _run_analysis_workflow(run_dir, system_name, run_name, psf_file, dcd_file,
                           run_gg, run_com, run_orientation, run_ion_tracking,
                           run_ion_coordination, run_water, run_gyration, run_tyrosine,
                           run_conduction,
                           run_dwgates, # Add dwgates
                           specific_analyses_requested,
                           generate_html,
                           box_z=None, force_rerun=False):
    """
    Internal helper function to execute the analysis steps for a single run.
    Handles skip logic based on flags.
    """
    summary_file_path = os.path.join(run_dir, 'analysis_summary.json')

    # --- Skip Logic (Revised based on flags) ---
    # Skip only if: NOT forcing rerun AND running FULL analysis (not selective) AND summary exists and is valid
    can_potentially_skip = not force_rerun and not specific_analyses_requested

    if can_potentially_skip and os.path.exists(summary_file_path):
        try:
            with open(summary_file_path, 'r') as f_check:
                existing_summary = json.load(f_check)
            previous_version = existing_summary.get('AnalysisScriptVersion')
            previous_status = existing_summary.get('AnalysisStatus', '')

            # Skip only if previous run was successful AND versions match.
            if previous_status.startswith('Success') and previous_version == Analysis_version:
                logging.info(f"Skipping successfully processed run (v{Analysis_version}, Full Analysis mode): {system_name}/{run_name}")
                # If skipping analysis but report was requested (e.g., via --force_rerun --report, though unlikely)
                # we still need to try and generate it from existing summary.
                if generate_html:
                     logging.info("Attempting to generate HTML report from existing summary...")
                     try:
                         with open(summary_file_path, 'r') as f_sum:
                             run_summary_for_html = json.load(f_sum)
                         generate_html_report(run_dir, run_summary_for_html)
                         logging.info("HTML report generated from existing summary.")
                     except Exception as e_html_skip:
                         logging.error(f"Failed to generate HTML report from existing summary after skipping: {e_html_skip}", exc_info=True)
                return True # Indicate successful skip (or skip + report gen)

            elif previous_version != Analysis_version:
                 logging.info(f"Reprocessing run (Full Analysis mode): Version mismatch (Prev: {previous_version}, Curr: {Analysis_version})")
            elif not previous_status.startswith('Success'):
                 logging.info(f"Reprocessing run (Full Analysis mode): Previous status was '{previous_status}'")

        except Exception as e_check:
            logging.warning(f"Could not read/parse existing summary {summary_file_path}, reprocessing (Full Analysis mode). Error: {e_check}")
    elif specific_analyses_requested:
         logging.info("Running in Selective Analysis mode. Skip check bypassed.")
    elif force_rerun:
         logging.info("Running with --force_rerun. Skip check bypassed.")


    # --- Initialize results --- (Add new keys)
    results = {
        'dist_ac': None, 'dist_bd': None, 'com_distances': None, 'time_points': None,
        'filtered_ac': None, 'filtered_bd': None, 'filtered_com': None,
        'filter_info_gg': {}, 'filter_info_com': {},
        'ions_z_g1_filtered': None, 'time_points_ions': None, 'ion_indices': [], # Updated ion keys
        'ions_z_abs': None, # Make sure this exists
        'g1_reference': None, 'filter_sites': None, 'filter_residues': None,
        'cavity_water_stats': {}, 'ion_transit_stats': {}, # Added ion transit stats
        'orientation_rotation_stats': {}, 'raw_dist_stats': {}, 'percentile_stats': {},
        'com_analyzed': False, # Flag: Was COM calculated?
        'is_control_system': False, # Flag: Is this a control system?
        'gyration_stats': {},
        'tyrosine_stats': {},
        'conduction_stats': {}, # Key for conduction results
        'dw_gate_stats': {}    # New key for DW gate results
    }

    # --- Execute Analyses ---
    # The logic for executing each analysis block based on run_gg, run_com, etc.
    # remains the same. The key change is that if specific_analyses_requested is True,
    # these steps will overwrite any existing output files for the specific modules run.
    try:
        # 1. Core Trajectory Analysis (G-G, COM Raw) - Always run if needed by subsequent steps
        # We run this if any of GG, COM, Orientation, IonTracking, Water, Gyration, Tyrosine needs it
        # Or if it's a full analysis run.
        core_needed = (run_gg or run_com or run_orientation or run_ion_tracking or
                       run_water or run_gyration or run_tyrosine or
                       run_conduction or run_dwgates) # Added conduction and dwgates
        if core_needed:
             logging.info("Running Core Trajectory Analysis (required for other modules)...")
             results['dist_ac'], results['dist_bd'], results['com_distances'], results['time_points'], _, results['is_control_system'] = \
                 analyze_trajectory(run_dir, psf_file=psf_file, dcd_file=dcd_file)
             results['com_analyzed'] = results['com_distances'] is not None

             # Update logs based on system type
             if results['is_control_system']:
                 logging.info(f"CONTROL system detected (no toxin) for {system_name}/{run_name}")
             else:
                 logging.info(f"Toxin-channel complex system detected for {system_name}/{run_name}")

             # Check if trajectory analysis returned valid time points
             if results['time_points'] is None or len(results['time_points']) == 0:
                  raise ValueError("Trajectory analysis failed to produce time points.")
        else:
             logging.info("Skipping Core Trajectory Analysis (not required by selected modules).")


        # 2. Filtering (if requested)
        if run_gg or run_com:
             # This block only runs if the flags --GG or --COM were set OR if it's a full run
             if not core_needed: # We need core results for filtering
                  raise RuntimeError("Cannot run filtering (--GG or --COM) without core trajectory analysis results.")
             logging.info(f"Running Filtering and Saving (GG={run_gg}, COM={run_com})...")
             results['filtered_ac'], results['filtered_bd'], results['filtered_com'], \
             results['filter_info_gg'], results['filter_info_com'], \
             results['raw_dist_stats'], results['percentile_stats'] = \
                 filter_and_save_data(
                     run_dir, results['dist_ac'], results['dist_bd'],
                     results['com_distances'], results['time_points'],
                     box_z=box_z,
                     is_control_system=results['is_control_system'] # Pass flag
                 )
             results['com_analyzed'] = results['com_distances'] is not None


        # 3. Ion Tracking (if requested or needed by water/conduction/coordination)
        ion_tracking_needed = run_ion_tracking or run_ion_coordination or run_water or run_conduction
        if ion_tracking_needed:
            logging.info("Running K+ Ion Tracking...")
            # ... (rest of ion tracking call and debug logging remains the same) ...
            ions_z_abs, time_points_ions, ion_indices, g1_ref, sites, filter_res_dict = \
                track_potassium_ions(run_dir, psf_file=psf_file, dcd_file=dcd_file)
            # === DEBUGGING ADDED ===
            logging.debug(f"track_potassium_ions returned:")
            logging.debug(f"  - ion_indices type: {type(ion_indices)}, len: {len(ion_indices) if ion_indices is not None else 'N/A'}")
            logging.debug(f"  - g1_ref type: {type(g1_ref)}, value: {g1_ref}")
            logging.debug(f"  - sites type: {type(sites)}, is_none: {sites is None}, keys: {list(sites.keys()) if isinstance(sites, dict) else 'N/A'}")
            logging.debug(f"  - filter_res_dict type: {type(filter_res_dict)}, is_none: {filter_res_dict is None}, keys: {list(filter_res_dict.keys()) if isinstance(filter_res_dict, dict) else 'N/A'}")
            # === END DEBUGGING ===
            # Assign to results dictionary
            results['ions_z_abs'] = ions_z_abs
            results['time_points_ions'] = time_points_ions
            results['ion_indices'] = ion_indices
            results['g1_reference'] = g1_ref
            results['filter_sites'] = sites
            results['filter_residues'] = filter_res_dict
        else:
            logging.info("Skipping K+ Ion Tracking (not required by selected modules).")


        # 4. Toxin Orientation/Contacts (if requested and NOT a control system)
        if run_orientation:
             if results['is_control_system']:
                 logging.info("Skipping Toxin Orientation analysis (control system without toxin).")
                 # Set empty rotation stats for control systems for consistency
                 results['orientation_rotation_stats'] = { # Set to None
                     'Orient_RotX_Mean': None, 'Orient_RotX_Std': None,
                     'Orient_RotY_Mean': None, 'Orient_RotY_Std': None,
                     'Orient_RotZ_Mean': None, 'Orient_RotZ_Std': None
                 }
             elif not results['com_analyzed']: # Requires COM analysis to have run
                 logging.warning("Skipping Toxin Orientation analysis (--orientation requested but COM prerequisites missing).")
                 results['orientation_rotation_stats'] = {}
             else:
                 logging.info("Running Toxin Orientation Analysis...")
                 # ... (rest of orientation call remains the same) ...
                 orientation_angles, rotation_euler_angles, contact_counts, residue_contact_df, rotation_stats_dict = \
                     analyze_toxin_orientation(dcd_file, psf_file, run_dir)
                 results['orientation_rotation_stats'] = rotation_stats_dict
        else:
             # If not run, ensure stats dict exists but is empty or nullified
             results['orientation_rotation_stats'] = { # Set to None
                 'Orient_RotX_Mean': None, 'Orient_RotX_Std': None,
                 'Orient_RotY_Mean': None, 'Orient_RotY_Std': None,
                 'Orient_RotZ_Mean': None, 'Orient_RotZ_Std': None
             }


        # 5. Ion Coordination (if requested)
        if run_ion_coordination:
            # Check prerequisites from ion tracking
            if results.get('ion_indices') is not None and results.get('filter_residues'):
                logging.info("Running K+ Ion Coordination Analysis...")
                # ... (rest of coordination call remains the same) ...
                try:
                    analyze_ion_coordination(
                        run_dir,
                        results['time_points_ions'],
                        results['ions_z_abs'],
                        results['ion_indices'],
                        results['filter_sites'],
                        results['g1_reference']
                    )
                except FileNotFoundError:
                    logging.error("Coordination: PSF or DCD file not found. Cannot load Universe.")
                except Exception as e_coord_setup:
                    logging.error(f"Coordination: Error during setup or execution: {e_coord_setup}", exc_info=True)
            else:
                logging.warning("Skipping Ion Coordination (--ions flag set, but prerequisites from ion tracking missing).")


        # 6. Ion Conduction (if requested)
        if run_conduction:
             # Check prerequisites from ion tracking
             if results.get('ion_indices') and results.get('filter_sites') and results.get('g1_reference') is not None and results.get('time_points_ions') is not None and results.get('ions_z_abs') is not None:
                 logging.info("Running Ion Conduction & Transition Analysis...")
                 # ... (rest of conduction call remains the same) ...
                 try:
                    results['conduction_stats'] = analyze_ion_conduction(
                        run_dir=run_dir,
                        time_points=results['time_points_ions'],
                        ions_z_positions=results['ions_z_abs'],
                        ion_indices=results['ion_indices'],
                        filter_sites=results['filter_sites'],
                        g1_reference=results['g1_reference']
                    )
                    logging.info(f"Ion Conduction Analysis completed. Total Transitions: {results['conduction_stats'].get('Ion_TransitionEvents_Total', 'N/A')}")

                    # Call the plotting function *after* analyze_ion_conduction
                    plot_idealized_transitions(
                        run_dir=run_dir,
                        time_points=results['time_points_ions'],
                        filter_sites=results['filter_sites'],
                        g1_reference=results['g1_reference'],
                        ions_z_positions=results['ions_z_abs'],
                        ion_indices=results['ion_indices']
                    )

                 except Exception as e_conduction:
                     logging.error(f"Ion Conduction analysis or plotting failed: {e_conduction}", exc_info=True)
                     results['conduction_stats'] = {} # Ensure key exists on error
             else:
                 logging.warning("Skipping Ion Conduction (--conduction flag set, but prerequisites from ion tracking missing).")
                 results['conduction_stats'] = {} # Ensure key exists


        # 7. Cavity Water (if requested)
        if run_water:
             # Check prerequisites from ion tracking
             if results.get('filter_sites') and results.get('filter_residues') \
                and isinstance(results.get('g1_reference'), (float, int, np.number)):
                 logging.info("Running Cavity Water Analysis...")
                 # ... (rest of water call remains the same) ...
                 results['cavity_water_stats'] = analyze_cavity_water(
                     run_dir, psf_file, dcd_file,
                     results['filter_sites'], results['g1_reference'], results['filter_residues']
                 )
             else:
                 logging.warning("Skipping Cavity Water analysis (--water flag set, but prerequisites from ion tracking missing).")


        # 8. Carbonyl Gyration Analysis (if requested)
        if run_gyration:
             logging.info("Running Carbonyl Gyration Analysis...")
             # ... (rest of gyration call remains the same) ...
             gyration_results = analyze_carbonyl_gyration(
                 run_dir=run_dir,
                 psf_file=psf_file,
                 dcd_file=dcd_file,
                 system_type="toxin" if not results.get('is_control_system', False) else "control"
             )
             results['gyration_stats'] = gyration_results
             flips = gyration_results.get('flips_detected', 'N/A')
             logging.info(f"Completed carbonyl gyration analysis: {flips} flips detected")
        else:
             # Ensure key exists even if empty if not run
             results['gyration_stats'] = {}


        # 9. SF Tyrosine Rotamer Analysis (if requested)
        if run_tyrosine:
             # Check prerequisites from ion tracking
             if results.get('filter_residues'):
                 logging.info("Running SF Tyrosine Rotamer Analysis...")
                 # ... (rest of tyrosine call remains the same) ...
                 tyrosine_results = analyze_sf_tyrosine_rotamers(
                     run_dir=run_dir,
                     psf_file=psf_file,
                     dcd_file=dcd_file,
                     filter_residues=results.get('filter_residues')
                 )
                 results['tyrosine_stats'] = tyrosine_results
             else:
                 logging.warning("Skipping SF Tyrosine analysis (--tyrosine flag set, but prerequisites from ion tracking missing).")
                 results['tyrosine_stats'] = {}
        else:
             # Ensure key exists even if empty if not run
             results['tyrosine_stats'] = {}


        # 10. DW Gate Analysis (if requested)
        if run_dwgates:
            # Check if the function was imported and prerequisites are met
            if analyse_dw_gates is None:
                logging.warning("Skipping DW Gate Analysis: Module/function could not be imported.")
                results['dw_gate_stats'] = {'Error': 'Module not imported'}
            elif results.get('time_points') is not None:
                 logging.info("Running DW Gate Analysis...")
                 try:
                     # Assuming default stride=1 for now, add stride param if needed
                     dw_stats = analyse_dw_gates(
                         run_dir=run_dir,
                         psf_file=psf_file,
                         dcd_file=dcd_file,
                         time_points=results['time_points'],
                         # stride=1 # Pass explicit stride if needed
                     )
                     results['dw_gate_stats'] = dw_stats
                     # Log a key result if available
                     global_closed = dw_stats.get('DWhbond_closed_global')
                     if global_closed is not None:
                         logging.info(f"DW Gate Analysis completed. Global Closed Fraction: {global_closed:.3f}")
                     else:
                         logging.info(f"DW Gate Analysis completed. Status: {dw_stats.get('Error', 'OK')}")
                 except FileNotFoundError:
                     logging.error("DW Gate: PSF or DCD file not found. Cannot load Universe.")
                     results['dw_gate_stats'] = {'Error': 'Input file not found'}
                 except Exception as e_dwg:
                     logging.error(f"DW Gate Analysis failed: {e_dwg}", exc_info=True)
                     results['dw_gate_stats'] = {'Error': str(e_dwg)}
            else:
                 logging.warning("Skipping DW Gate Analysis (--dwgates flag set, but time_points missing).")
                 results['dw_gate_stats'] = {'Error': 'Prerequisite time_points missing'}


        # --- Post-Analysis ---

        # 11. Calculate and Save Final Summary JSON
        # This runs regardless of specific flags, using whatever data is in results
        logging.info("Calculating and saving summary JSON...")
        # ... (calculate_and_save_run_summary call remains the same) ...
        calculate_and_save_run_summary(
            run_dir, system_name, run_name,
            results.get('com_analyzed', False),
            results.get('filter_info_com', {}),
            results.get('ion_indices', []),
            results.get('cavity_water_stats', {}),
            raw_dist_stats=results.get('raw_dist_stats', {}),
            percentile_stats=results.get('percentile_stats', {}),
            orientation_rotation_stats=results.get('orientation_rotation_stats', {}),
            ion_transit_stats=results.get('ion_transit_stats', {}),
            gyration_stats=results.get('gyration_stats', {}),
            tyrosine_stats=results.get('tyrosine_stats', {}),
            conduction_stats=results.get('conduction_stats', {}),
            dw_gate_stats=results.get('dw_gate_stats', {}),
            is_control_system=results.get('is_control_system', False)
        )


        # 12. Generate HTML Report (if requested by generate_html flag)
        if generate_html:
            logging.info("Generating HTML Report...")
            # Load the freshly saved summary to pass to HTML generator
            try:
                with open(summary_file_path, 'r') as f_sum:
                    run_summary_for_html = json.load(f_sum)
                generate_html_report(run_dir, run_summary_for_html)
            except FileNotFoundError:
                 logging.error(f"Could not find summary file {summary_file_path} to generate HTML report.")
            except Exception as e_html:
                 logging.error(f"Failed to generate HTML report: {e_html}", exc_info=True)
        else:
             logging.info("Skipping HTML report generation (conditions not met: see --report/--no-report flags and analysis mode).")


        return True # Success

    except Exception as e:
        logging.error(f"Workflow failed for {run_dir}: {e}", exc_info=True)
        _save_error_summary(run_dir, system_name, run_name, f"WorkflowError: {e}")
        return False # Failure

def _save_error_summary(run_dir, system_name, run_name, error_message):
    """Helper to save a minimal summary JSON when a critical error occurs."""
    summary_file_path = os.path.join(run_dir, 'analysis_summary.json')
    error_summary = {
        'SystemName': system_name,
        'RunName': run_name,
        'RunPath': run_dir,
        'AnalysisStatus': f'FAILED: {str(error_message)[:150]}', # Truncate long errors
        'AnalysisScriptVersion': Analysis_version,
        'AnalysisTimestamp': datetime.now().isoformat()
    }
    try:
        cleaned_summary = clean_json_data(error_summary) # Clean just in case
        with open(summary_file_path, 'w') as f_json:
            json.dump(cleaned_summary, f_json, indent=4)
        logging.info(f"Saved error status to {summary_file_path}")
    except Exception as e_save:
        logging.error(f"Failed to save error summary JSON to {summary_file_path}: {e_save}")

if __name__ == "__main__":
    main()
    logging.info(f"--- MD Analysis Script v{Analysis_version} Finished ---")
