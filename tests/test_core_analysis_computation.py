import pytest
import os
import numpy as np
import pandas as pd
import sqlite3
from pathlib import Path

# Adapt imports for refactored code
from pore_analysis.core.database import init_db, connect_db, get_module_status, get_product_path, get_all_metrics, get_simulation_metadata
from pore_analysis.modules.core_analysis.computation import analyze_trajectory, filter_and_save_data

# Fixture to create a dummy PSF and DCD file
@pytest.fixture
def dummy_md_files(tmp_path):
    run_dir = tmp_path / "dummy_run"
    run_dir.mkdir()
    psf_content = """PSF

      1 !NTITLE
 REMARKS generated by VMD
 REMARKS topology ../../common/top_all36_prot.rtf
 REMARKS default

       8 !NATOM
       1 ALA  1    ALA  N    NH3    -0.300000       14.0100           0   0.00000      -1.340000E-07
       2 ALA  1    ALA  HT1  HC      0.330000        1.0080           0   0.00000      -1.340000E-07
       3 ALA  1    ALA  HT2  HC      0.330000        1.0080           0   0.00000      -1.340000E-07
       4 ALA  1    ALA  HT3  HC      0.330000        1.0080           0   0.00000      -1.340000E-07
       5 ALA  1    ALA  CA   CT1     0.070000       12.0100           0   0.00000      -1.340000E-07
       6 ALA  1    ALA  HA   HB1     0.090000        1.0080           0   0.00000      -1.340000E-07
       7 ALA  1    ALA  C    C       0.510000       12.0100           0   0.00000      -1.340000E-07
       8 ALA  1    ALA  O    O      -0.510000       16.0000           0   0.00000      -1.340000E-07

       0 !NBOND


       0 !NTHETA


       0 !NPHI


       0 !NIMPHI


       0 !NDON


       0 !NACC


       0 !NNB

       0       0       0       0

       1       1       0 !NGRP
"""
    dcd_header = np.array([84, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 67, 79, 82, 68], dtype=np.int32).tobytes()
    dcd_frame_header = np.array([48], dtype=np.int32).tobytes()
    dcd_coords = np.arange(8*3*2, dtype=np.float32).reshape(2, 8, 3) # 2 frames, 8 atoms
    dcd_frame_footer = np.array([48], dtype=np.int32).tobytes()
    psf_path = run_dir / "step5_input.psf"
    dcd_path = run_dir / "MD_Aligned.dcd"
    with open(psf_path, "w") as f:
        f.write(psf_content)
    with open(dcd_path, "wb") as f:
        f.write(dcd_header)
        f.write(dcd_frame_header)
        f.write(dcd_coords[0].tobytes())
        f.write(dcd_frame_footer)
        f.write(dcd_frame_header)
        f.write(dcd_coords[1].tobytes())
        f.write(dcd_frame_footer)

    return run_dir, psf_path, dcd_path

# === Tests for analyze_trajectory ===

def test_analyze_trajectory_success(dummy_md_files):
    """Test basic successful run of analyze_trajectory (computation only)."""
    run_dir, psf_path, dcd_path = dummy_md_files
    # Initialize DB before running
    conn = init_db(str(run_dir))
    assert conn is not None
    conn.close()

    # Call the function
    results = analyze_trajectory(str(run_dir), psf_file=str(psf_path), dcd_file=str(dcd_path))

    # Assertions
    assert results['status'] == 'success'
    assert 'data' in results
    assert 'dist_ac' in results['data'] # Should exist, even if all NaN due to dummy data
    assert 'dist_bd' in results['data']
    assert 'time_points' in results['data']
    assert 'metadata' in results
    assert results['metadata']['is_control_system'] is True # Dummy data likely won't have toxin segid
    assert 'files' in results
    assert 'raw_distances' in results['files']

    # Check DB status
    conn = connect_db(str(run_dir))
    assert get_module_status(conn, "core_analysis") == "success"
    # Check product registered
    prod_path = get_product_path(conn, "csv", "data", "raw_distances", module_name="core_analysis")
    assert prod_path == "core_analysis/Raw_Distances.csv"
    conn.close()

    # Check file exists
    raw_csv = run_dir / prod_path
    assert raw_csv.exists()

def test_analyze_trajectory_missing_files(tmp_path):
    """Test analyze_trajectory when PSF/DCD are missing."""
    run_dir = tmp_path / "run_missing"
    run_dir.mkdir()
    # No DB needed as it fails before DB ops
    results = analyze_trajectory(str(run_dir))

    assert results['status'] == 'failed'
    assert 'PSF file not found' in results['error']
    # Check the fallback data structure exists but might be empty/default
    assert 'data' in results
    assert 'metadata' in results

    # Test missing DCD
    psf_path = run_dir / "step5_input.psf"
    psf_path.touch() # Create dummy PSF
    results_dcd = analyze_trajectory(str(run_dir))
    assert results_dcd['status'] == 'failed'
    assert 'DCD file not found' in results_dcd['error']

def test_analyze_trajectory_0_frames(tmp_path):
    """Test analyze_trajectory with a 0-frame DCD (requires setup)."""
    run_dir = tmp_path / "run_0frame"
    run_dir.mkdir()
    psf_path = run_dir / "step5_input.psf"
    dcd_path = run_dir / "MD_Aligned.dcd"
    # Create dummy PSF
    psf_path.write_text("PSF\n\n 1 !NATOM\n 1 A 1 A N N 0 14 0\n 0 !NBOND")
    # Create dummy DCD header indicating 0 frames
    dcd_header = np.array([84, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 67, 79, 82, 68], dtype=np.int32).tobytes()
    with open(dcd_path, "wb") as f:
        f.write(dcd_header)

    # Initialize DB
    conn = init_db(str(run_dir))
    conn.close()

    results = analyze_trajectory(str(run_dir))
    assert results['status'] == 'failed'
    assert '0 frames' in results['error']

    conn = connect_db(str(run_dir))
    assert get_module_status(conn, "core_analysis") == "failed"
    conn.close()


# === Tests for filter_and_save_data ===

def test_filter_and_save_data_success(tmp_path):
    """Test successful filtering and saving."""
    run_dir = tmp_path / "run_filter"
    run_dir.mkdir()
    conn = init_db(str(run_dir))

    # Dummy raw data
    time_points = np.linspace(0, 9, 10)
    dist_ac = time_points + np.random.rand(10) * 0.1 # Simple trend + noise
    dist_bd = time_points * 0.8 + np.random.rand(10) * 0.1 + 5.0
    dist_com = time_points * 2 + np.random.rand(10) * 0.2 + 10.0

    # Run filtering
    results = filter_and_save_data(
        run_dir=str(run_dir),
        dist_ac=dist_ac,
        dist_bd=dist_bd,
        com_distances=dist_com,
        time_points=time_points,
        db_conn=conn, # Pass the connection
        box_z=None,
        is_control_system=False
    )

    # Assertions
    assert results['status'] == 'success'
    assert 'data' in results
    assert 'filtered_ac' in results['data'] and len(results['data']['filtered_ac']) == 10
    assert 'filtered_bd' in results['data'] and len(results['data']['filtered_bd']) == 10
    assert 'filtered_com' in results['data'] and len(results['data']['filtered_com']) == 10
    assert 'files' in results
    assert 'g_g_distance_filtered' in results['files']
    assert 'com_stability_filtered' in results['files']
    assert 'errors' in results and not results['errors'] # Should be no errors

    # Check DB
    assert get_module_status(conn, "core_analysis_filtering") == "success"
    gg_path = get_product_path(conn, "csv", "data", "g_g_distance_filtered")
    com_path = get_product_path(conn, "csv", "data", "com_stability_filtered")
    assert gg_path == "core_analysis/G_G_Distance_Filtered.csv"
    assert com_path == "core_analysis/COM_Stability_Filtered.csv"

    # Check metrics were stored
    metrics = get_all_metrics(conn) # Fetch all metrics for simplicity
    assert 'G_G_AC_Mean_Filt' in metrics
    assert 'G_G_BD_Mean_Filt' in metrics
    assert 'COM_Mean_Filt' in metrics
    assert 'G_G_AC_Std_Filt' in metrics
    assert 'COM_Std_Filt' in metrics

    # Check CSV files exist
    gg_csv = run_dir / gg_path
    com_csv = run_dir / com_path
    assert gg_csv.exists()
    assert com_csv.exists()

    conn.close()


def test_filter_and_save_data_control_system(tmp_path):
    """Test filtering for a control system (no COM)."""
    run_dir = tmp_path / "run_filter_control"
    run_dir.mkdir()
    conn = init_db(str(run_dir))

    time_points = np.linspace(0, 9, 10)
    dist_ac = time_points + np.random.rand(10) * 0.1
    dist_bd = time_points * 0.8 + np.random.rand(10) * 0.1 + 5.0

    results = filter_and_save_data(
        run_dir=str(run_dir),
        dist_ac=dist_ac,
        dist_bd=dist_bd,
        com_distances=None, # No COM data
        time_points=time_points,
        db_conn=conn,
        is_control_system=True # Mark as control
    )

    assert results['status'] == 'success'
    assert 'com_stability_filtered' not in results['files'] # COM file shouldn't be created/registered
    assert not results['data']['filtered_com'] # Filtered COM should be empty

    # Check DB
    assert get_module_status(conn, "core_analysis_filtering") == "success"
    com_path = get_product_path(conn, "csv", "data", "com_stability_filtered")
    assert com_path is None # Should not be registered
    metrics = get_all_metrics(conn)
    assert 'COM_Mean_Filt' not in metrics # No COM metrics

    conn.close()


def test_filter_and_save_data_no_db_conn(tmp_path):
    """Test failure when DB connection is not provided."""
    run_dir = tmp_path / "run_filter_nodb"
    run_dir.mkdir()
    # No DB init

    time_points = np.linspace(0, 9, 10)
    dist_ac = time_points + np.random.rand(10) * 0.1
    dist_bd = time_points * 0.8 + np.random.rand(10) * 0.1 + 5.0

    results = filter_and_save_data(
        run_dir=str(run_dir),
        dist_ac=dist_ac,
        dist_bd=dist_bd,
        com_distances=None,
        time_points=time_points,
        db_conn=None, # Pass None for DB connection
        is_control_system=True
    )

    assert results['status'] == 'failed'
    assert 'Database connection was not provided' in results['error']

